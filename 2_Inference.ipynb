{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre settings of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import RobertaTokenizerFast, \\\n",
    "RobertaModel, Trainer, TrainingArguments,EvalPrediction, TrainerCallback\n",
    "\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel, RobertaClassificationHead\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the cuda and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch cuda version:  11.8\n",
      "Torch cuda is enabled:  True\n",
      "Using device: cuda\n",
      "Device name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print('Torch cuda version: ', torch.version.cuda)\n",
    "print('Torch cuda is enabled: ', torch.backends.cudnn.enabled)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == 'cuda':\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Define the path where your model is saved\n",
    "model_path = 'roberta_trainer'\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "# Load the tokenizer (if you saved it)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Vice President / Director of Systems Engineering</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>CTO/Executive Director of Technology Services</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Chief Information Officer, Platform Services</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Chief Information Systems Officer</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Vice President, Chief Information Security Off...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2004</td>\n",
       "      <td>Paraplanning, Operations Manager</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2006</td>\n",
       "      <td>Group Finance Reporting Manager</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2012</td>\n",
       "      <td>Indirect Tax Technology Manager</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2016</td>\n",
       "      <td>Manager Manufacturing Engineering</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2021</td>\n",
       "      <td>Department Manager System Validation I Global ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              Title  \\\n",
       "0       0   Vice President / Director of Systems Engineering   \n",
       "1       3      CTO/Executive Director of Technology Services   \n",
       "2       6       Chief Information Officer, Platform Services   \n",
       "3       8                  Chief Information Systems Officer   \n",
       "4      10  Vice President, Chief Information Security Off...   \n",
       "..    ...                                                ...   \n",
       "441  2004                   Paraplanning, Operations Manager   \n",
       "442  2006                    Group Finance Reporting Manager   \n",
       "443  2012                    Indirect Tax Technology Manager   \n",
       "444  2016                  Manager Manufacturing Engineering   \n",
       "445  2021  Department Manager System Validation I Global ...   \n",
       "\n",
       "                 Labels  \n",
       "0    [0, 0, 0, 0, 0, 1]  \n",
       "1    [1, 1, 0, 0, 0, 0]  \n",
       "2    [1, 0, 0, 0, 0, 0]  \n",
       "3    [1, 0, 0, 0, 0, 0]  \n",
       "4    [1, 0, 0, 0, 0, 0]  \n",
       "..                  ...  \n",
       "441  [0, 0, 0, 1, 0, 0]  \n",
       "442  [0, 0, 0, 1, 0, 0]  \n",
       "443  [0, 0, 0, 1, 0, 0]  \n",
       "444  [0, 0, 0, 1, 0, 0]  \n",
       "445  [0, 0, 0, 1, 0, 0]  \n",
       "\n",
       "[446 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_test = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "title_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the Data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a class that will handle the data\n",
    "class Data_Processing_test():\n",
    "    def __init__(self, tokenizer, id_column, text_column):\n",
    "        \n",
    "        # define the text column from the dataframe\n",
    "        self.text_column = text_column.tolist()\n",
    "                    \n",
    "        # define the id column and transform it to list\n",
    "        self.id_column = id_column.tolist()\n",
    "            \n",
    "# Iter method to get each element at the time and tokenize it using bert        \n",
    "    def __getitem__(self, index):\n",
    "        comment_text = str(self.text_column[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "        \n",
    "        inputs = tokenizer.encode_plus(comment_text,\n",
    "                                       add_special_tokens = True,\n",
    "                                       max_length= 512,\n",
    "                                       padding = 'max_length',\n",
    "                                       return_attention_mask = True,\n",
    "                                       truncation = True,\n",
    "                                       return_tensors='pt')\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        id_ = self.id_column[index]\n",
    "        return {'input_ids':input_ids[0], 'attention_mask':attention_mask[0], \n",
    "                'id_':id_}\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.text_column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "# Create a class to process the traininga and test data\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base',\n",
    "                                          padding = 'max_length',\n",
    "                                          truncation=True, \n",
    "                                          max_length = 512)\n",
    "test_data_pred =  Data_Processing_test(tokenizer,\n",
    "                                       title_test['Id'], \n",
    "                                       title_test['Title'])\n",
    "\n",
    "# Use the dataloaders class to load the data\n",
    "dataloaders_dict = {'test': DataLoader(test_data_pred,\n",
    "                                                 batch_size=batch_size, shuffle=True, num_workers=2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings and Prediction Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 7/7 [00:05<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "def prediction_and_embeddings():\n",
    "    prediction_data_frame_list = []\n",
    "    embeddings_data_frame_list = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloaders_dict['test'], desc=\"Predicting\")):  # wrap the loop with tqdm\n",
    "            inputs = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            # Feed the sequences to the model, specifying the attention mask\n",
    "            outputs = model(inputs, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            \n",
    "            hidden_states = outputs.hidden_states\n",
    "            last_hidden_states = hidden_states[-1].mean(dim=1).cpu().numpy()\n",
    "\n",
    "            ids = np.array(batch['id_'])\n",
    "            embeddings_df = pd.DataFrame(last_hidden_states, index=ids)\n",
    "            embeddings_data_frame_list.append(embeddings_df)\n",
    "\n",
    "            # Apply sigmoid to get probabilities\n",
    "            sigmoid = torch.nn.Sigmoid()\n",
    "            probs = sigmoid(torch.Tensor(outputs[0].detach().cpu().data.numpy()))\n",
    "            \n",
    "            # Convert probabilities to numpy array\n",
    "            probs = np.array(probs)\n",
    "            \n",
    "            # Store predictions\n",
    "            y_pred = np.zeros(probs.shape)\n",
    "            y_pred = probs\n",
    "            temp_data = pd.DataFrame(zip(batch['id_'], probs), columns=['id', 'target'])\n",
    "            prediction_data_frame_list.append(temp_data)\n",
    "\n",
    "    embeddings_file = 'test_embeddings.csv'\n",
    "    predictions_file = 'test_predictions.csv'\n",
    "    binary_predictions_file = 'test_binary_predictions.csv'\n",
    "\n",
    "    all_embeddings_df = pd.concat(embeddings_data_frame_list)\n",
    "    all_embeddings_df.to_csv(embeddings_file, index_label='id')\n",
    "\n",
    "    prediction_df = pd.concat(prediction_data_frame_list)\n",
    "    prediction_df['id'] = prediction_df['id'].apply(lambda x: int(x.item()))\n",
    "    prediction_df[['Chief Officer', 'Director', 'Individual Contributor/Staff',\n",
    "             'Manager', 'Owner', 'Vice President']] = pd.DataFrame(prediction_df.target.tolist(), index=prediction_df.index)\n",
    "    prediction_df = prediction_df.drop(columns='target')\n",
    "    prediction_df.to_csv(predictions_file, index=False)\n",
    "\n",
    "    binary_predictions_df = prediction_df.copy()\n",
    "    binary_predictions_df.iloc[:, 1:] = (prediction_df.iloc[:, 1:] > 0.5).astype(int)\n",
    "    binary_predictions_df.to_csv(binary_predictions_file, index=False)\n",
    "\n",
    "prediction_and_embeddings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
